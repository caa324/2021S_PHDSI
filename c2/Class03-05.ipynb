{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with numerical and categorical data\n",
    "\n",
    "It can be difficult to understand a dataset by looking at each individual observation.\n",
    "We need methods to distill our data down into a smaller number of characteristics that can capture as much as possible  our original dataset.\n",
    "We'll spend the next two weeks looking exclusively at ways to summarize our data with statistics and visualize our data, making it easier to communicate relationships between biological phenomena. \n",
    "\n",
    "Statistics and visualizations capture key qualities of our data.\n",
    "Statistics often compress our data down into a small set of numerical values and can be incldued in a scientific report, or other communication.\n",
    "Below we provide a general definition of a statistic, and the corresponding parameter, and discuss desirable properties of a statistic. \n",
    "Though statistics offer a convienant summary of a dataset, they do not allow us access to every observation from the original dataset.\n",
    "\n",
    "Visualizations can be made for a small set of statistics, however, a major stremgth of visulizations is their ability to report all observations from a dataset, taking advantage of our ability to see patterns in data as a method of summary. \n",
    "Visualizations do not compress the data for us, rather they facilitate our ability to compress the data. \n",
    "\n",
    "Our goal for this week is to\n",
    " * Understand populations, samples, parameters, and statistics\n",
    " * Learn about frequently used statistic to summarize numerical and categorical data\n",
    " * Explore methods of visualizing data\n",
    " * Study a small number of ways to understand relationships between two variables. \n",
    "\n",
    "\n",
    "## Parameters are to the population as Statistics are to the sample\n",
    "\n",
    "When we study the output a specific variable it is helpful to think of properties that belong to the **population** compared to properties that belong to your **sample**.\n",
    "If you remember from last week, a **population** is the set of all possible observations of a variable.\n",
    "We often denote the number of observations in the population, the number of all observations, with the letter $N$.\n",
    "When we collect data from the population we take a **sample** a random subset of all observations. \n",
    "We often denote the number of observations in the **sample** with the letter $n$.\n",
    "\n",
    "A **parameter** is any function from a population to the real number line (negative and positive numbers including decimals) and a **statistic** is any function from a sample dataset to the real number line,\n",
    "\\begin{align}\n",
    "    f(\\mathcal{D}) \\to \\mathcal{R}. \n",
    "\\end{align}\n",
    "where $\\mathcal{D}$ is the set of all observations when we compute a **parameter** and is a subset of all observations when we compute a **statistic**, and $\\mathcal{R}$ is the real number line.\n",
    "This mathematical definition of a parameter and a statistic is broad, and you'll find some params/stats capture qualities of your data better than others.\n",
    "\n",
    "As an example of applying the definition of statistic, consider a dataset $\\mathcal{D}$ with 10 observations (rows) and 3 variables (columns) named $v_{1},v_{2}$, and $v_{3}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         v1        v2        v3\n",
      "0  0.709987  0.008341  0.710678\n",
      "1  0.314621  0.234253  0.118566\n",
      "2  0.256121  0.822209  0.545637\n",
      "3  0.113084  0.904368  0.204145\n",
      "4  0.165281  0.977053  0.167527\n",
      "5  0.192744  0.330994  0.148759\n",
      "6  0.048276  0.873247  0.901643\n",
      "7  0.871867  0.967601  0.968328\n",
      "8  0.955311  0.550778  0.365178\n",
      "9  0.621940  0.930925  0.994026\n"
     ]
    }
   ],
   "source": [
    "# generate random dataaset with 10 rows and 3 columns\n",
    "D = { \"v1\":[], \"v2\":[], \"v3\":[] } # first create a dictionary with 3 keys and empty lists as values\n",
    "for col,vals in D.items(): # loop through the columns\n",
    "    D[col] = list(np.random.random(size=10)) # a list of 10 random numbers between 0 and 1\n",
    "D = pd.DataFrame(D) # convert our dictionary into a pandas dataframe\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a statistic $S(v_{1})$ that computes the sum of $v_{1}$\n",
    "\\begin{align}\n",
    "    S(v_{1}) = \\sum_{\\text{obs}=1}^{10} \\mathcal{D}[ \\text{obs}, v_{1}]\n",
    "\\end{align}\n",
    "where $S(v_{1})$ is our statistic, $\\sum$ is the summation operator, and $\\mathcal{D}[ \\text{obs}, v_{1}]$ is the \"obs\" row and $v_{1}$ column of our dataset.\n",
    "In words, our statistic takes the sum of the $v_{1}$ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S(v1) = 4.25\n"
     ]
    }
   ],
   "source": [
    "Sv1 = D[\"v1\"].sum()\n",
    "print(\"S(v1) = {:.2f}\".format(Sv1)) # take a look at this syntax here: https://pyformat.info/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S(v_{1})$ is a statistic because it takes as input our dataset $\\mathcal{D}$ (generated above) and outputs a decimal number, a number that is a member of the real number line.\n",
    "\n",
    "Statistics like $S(v_{1})$ are not specific to a single generated dataset, but rather a specific data structure.\n",
    "Our statistic $S(v_{1})$ requires our dataset $\\mathcal{D}$ have a variable $v_{1}$.\n",
    "There are no restrictions on the number of observations (rows) or on what type of data $v_{1}$ refers to.\n",
    "\n",
    "We could have had $100$ observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          v1        v2        v3\n",
      "0   0.111765  0.259112  0.426872\n",
      "1   0.533311  0.535211  0.624941\n",
      "2   0.697459  0.327226  0.786404\n",
      "3   0.150202  0.055467  0.391050\n",
      "4   0.338611  0.643141  0.060149\n",
      "5   0.088781  0.717805  0.716647\n",
      "6   0.399962  0.541522  0.286285\n",
      "7   0.789399  0.477639  0.092080\n",
      "8   0.987552  0.841219  0.693240\n",
      "9   0.841058  0.063964  0.083979\n",
      "10  0.993848  0.621953  0.796496\n",
      "11  0.067171  0.385016  0.593295\n",
      "12  0.450541  0.371491  0.662814\n",
      "13  0.618060  0.249434  0.295322\n",
      "14  0.761381  0.265513  0.814782\n",
      "S(v1) = 51.96 with 100 observations\n"
     ]
    }
   ],
   "source": [
    "# generate random dataaset with 10 rows and 3 columns\n",
    "D = { \"v1\":[], \"v2\":[], \"v3\":[] } # first create a dictionary with 3 keys and empty lists as values\n",
    "for col,vals in D.items(): # loop through the columns\n",
    "    D[col] = list(np.random.random(size=10**2)) # a list of 100 random numbers between 0 and 1\n",
    "D = pd.DataFrame(D) # convert our dictionary into a pandas dataframe\n",
    "\n",
    "print(D.head(15))\n",
    "\n",
    "Sv1 = D[\"v1\"].sum()\n",
    "print(\"S(v1) = {:.2f} with 100 observations\".format(Sv1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or $v_{1}$ could refer to categories of data that take the values 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    v1  v2  v3\n",
      "0    0   0   1\n",
      "1    1   0   1\n",
      "2    1   1   1\n",
      "3    1   1   1\n",
      "4    0   0   1\n",
      "5    0   0   0\n",
      "6    0   0   1\n",
      "7    1   1   1\n",
      "8    1   0   0\n",
      "9    0   0   1\n",
      "10   0   0   1\n",
      "11   1   1   1\n",
      "12   0   0   0\n",
      "13   0   1   1\n",
      "14   1   1   1\n",
      "S(v1) = 47.00 with v1 a variable that takes values of 0 or 1\n"
     ]
    }
   ],
   "source": [
    "# generate random dataaset with 10 rows and 3 columns\n",
    "D = { \"v1\":[], \"v2\":[], \"v3\":[] } # first create a dictionary with 3 keys and empty lists as values\n",
    "for col,vals in D.items(): # loop through the columns\n",
    "    D[col] = [ 1 if np.random.random() > 0.5 else 0 for i in range(100)]\n",
    "D = pd.DataFrame(D) # convert our dictionary into a pandas dataframe\n",
    "\n",
    "print(D.head(15))\n",
    "Sv1 = D[\"v1\"].sum()\n",
    "print(\"S(v1) = {:.2f} with v1 a variable that takes values of 0 or 1\".format(Sv1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics play a central role in data science.\n",
    "We will explore a diverse range of methods for summarizing data and explaining relationships between one or more variables. \n",
    "Our goal will be to understand the entire analysis pipeline: from data collection to a final report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing and summarizing numerical data\n",
    "\n",
    "Numerical data is defined as a set of observations whose values are elements of the real line (positive and negative numbers, including decimals). \n",
    "\n",
    "# Example dataset\n",
    "We will explore a dataset collected by members of the California Safe Cosmetics Program (CSCP)\n",
    "The CSCP states that their primary purpose is to collect information on potentially hazardous chemicals or ingredients put into cosmetics products.\n",
    "\n",
    "Cosmetic products sold in California must report any ingredients suspected to cause cancer or reproductive harm---the list of reported ingredients can be found [here](https://www.cdph.ca.gov/Programs/CCDPHP/DEODC/OHB/CSCP/CDPH%20Document%20Library/chemlist.pdf).\n",
    "To better inform consumers and policy/decision makers, the CSCP compiles data on these products \n",
    "where each row (observation) is a cosmetic product and all variables are in columns. \n",
    "A full description of the dataset is [here.](https://healthdata.gov/dataset/chemicals-cosmetics)\n",
    "\n",
    "We will focus in our examples on products for hair care. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset is in CSV format and pandas can import directly from a https request\n",
    "data = pd.read_csv(\"https://data.chhs.ca.gov/dataset/596b5eed-31de-4fd8-a645-249f3f9b19c4/resource/57da6c9a-41a7-44b0-ab8d-815ff2cd5913/download/cscpopendata.csv\")\n",
    "hairCareProducts = data[data.PrimaryCategoryId==18] # haircare products are all recorded as category id 18\n",
    "\n",
    "numOfObservations = len(hairCareProducts)\n",
    "print(\"There are {:d}\".format(numOfObservations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was taken from the above URL and subset to Category 18 products: hair care products.\n",
    "As a brief summary of the data, we can look at how many different chemicals are reported in hair care products and the distribution of the sum of the number of potentially hazard chemicals per company.\n",
    "\n",
    "First the types of chemicals reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typesOfChemicals = hairCareProducts.ChemicalName.unique() # lets look at the types of chemicals that are reported\n",
    "print(\"Types of recorded chemicals ({:d} in total)\".format(len(typesOfChemicals)) )\n",
    "\n",
    "for chemicalType in typesOfChemicals:\n",
    "    print( \"Chemical type = {:s}\".format(chemicalType) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per company, sum up the total number of chemicals included in their products\n",
    "def countNumberOfChems(subsetOfData):\n",
    "    return pd.Series({\"totalNumOfChems\":subsetOfData.ChemicalCount.sum()})\n",
    "sumOfChemsPerCompany = hairCareProducts.groupby([\"CompanyId\"]).apply(countNumberOfChems)\n",
    "\n",
    "# min number of products\n",
    "print(\"The min number of haz chems {:d}\".format(sumOfChemsPerCompany.totalNumOfChems.min()))\n",
    "\n",
    "# max number of products\n",
    "print(\"The min number of haz chems {:d}\".format(sumOfChemsPerCompany.totalNumOfChems.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for companyID,companyChems in sumOfChemsPerCompany.iterrows():\n",
    "    print(\"Compay={:d}, Total number of potentially hazardous chemicals = {:d}\".format(companyID,companyChems.totalNumOfChems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we can see the total number of potentially hazardous chemicals each company includes in their haircare products, it might be easier to explain this data by using summary statistics. \n",
    "\n",
    "## The mean\n",
    "The first summary statistic is the mean---often called the average.\n",
    "Suppose you have a single column of data (i.e. a single variable) that produces numerical values.  We can represent the column as a variable $X$, knowing that $X$ contains a list of ($n$) numerical values\n",
    "\n",
    "\\begin{align}\n",
    "    X = [x_{1},x_{2},\\cdots,x_{n}]\n",
    "\\end{align}\n",
    "\n",
    "where $x_{1}, x_{2}$ and so are meant to represent numerical values.\n",
    "For example,\n",
    "\\begin{align}\n",
    "    X = [1.4,-0.56,23.45,7]\n",
    "\\end{align}\n",
    "\n",
    "The mean $\\bar{X}$ is computed as \n",
    "\n",
    "\\begin{align}\n",
    "    \\bar{X} = (x_{1} + x_{2} + x_{3} + \\cdots x_{n})/n\n",
    "\\end{align}\n",
    "\n",
    "or the sum of all numerical values divided by the number of numerical values considered ($n$).\n",
    "You may have heard that the mean describes the \"central tendency\" of your variable, a number future values of this variable may take. \n",
    "We'll find out why this is the case after we cover basic probability.\n",
    "\n",
    "***\n",
    "\n",
    "## Aside (Sigma Notation)\n",
    "\n",
    "We can write the mean of a variable $X$ in a more compact form than we have above.\n",
    "The key is using the symbol $\\sum$.\n",
    "\n",
    "Mathematicians typically use the symbol $\\sum$ to stand for summing up a set of variables.\n",
    "The set of variables can be assigned in a few different ways. \n",
    "The first way is to assign a value called an index to each number in the set you want to sum, then you can define \n",
    "\n",
    "\\begin{align}\n",
    "    \\sum_{i=1}^{N} x_{i} = x_{1}+x_{2}+x_{3}+\\cdots+x_{N}\n",
    "\\end{align}\n",
    "\n",
    "where the above symbol means $x_{1}+x_{2}+x_{3}+\\cdots+x_{N}$, or \"sum up all the values from x_{1} to x_{N}\". \n",
    "For example, I can define the variable $X=[1.4,-0.56,23.45,7]$ and assign\n",
    "* $x_{1} = 1.4$\n",
    "* $x_{2} = -0.56$\n",
    "* $x_{3} = 23.45$\n",
    "* $x_{4} = 7$\n",
    "\n",
    "Then $\\sum_{i=1}^{4} x_{i} = x_{1}+x_{2}+x_{3}+x_{4} = 1.4 + (-0.56) + 23.45 + 7 = 31.29$\n",
    "\n",
    "Another way to define the set of number to sum is to place the set of indices underneath the $\\sum$ symbol.\n",
    "For example, \n",
    "\\begin{align}\n",
    "    \\sum_{i \\in {1,2,3,4} } x_{i} = x_{1}+x_{2}+x_{3}+x_{4}\n",
    "\\end{align}\n",
    "\n",
    "Another example, summing the 1st and third values could be written\n",
    "\n",
    "\\begin{align}\n",
    "    \\sum_{i \\in {1,3} } x_{i} = x_{1}+x_{3}\n",
    "\\end{align}\n",
    "\n",
    "A third way to define a sum is by defining the set of indices to sum with a conditional statement. \n",
    "For example, suppose we want to sum all the values with indices less than 3. \n",
    "We can write\n",
    "\n",
    "\\begin{align}\n",
    "    \\sum_{i < 3 } x_{i} = x_{1}+x_{2}\n",
    "\\end{align}\n",
    "\n",
    "***\n",
    "\n",
    "We can rewrite the mean in a more compact form by using $\\sum$ notation \n",
    "\n",
    "\\begin{align}\n",
    "    \\bar{X} = \\dfrac{\\sum_{i=1}^{N} x_{i}}{N}\n",
    "\\end{align}\n",
    "\n",
    "where $N$ is the total number of data points for the variable $X$.\n",
    "\n",
    "Let's look at the average number of potentially hazardous chemicals companies place in their hair care products as reported by the California Safe Cosmetics Program (CSCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanNumberOfChemicals = sumOfChemsPerCompany.mean()  # take mean of number of potenitally haz chemicals \n",
    "meanNumberOfChemicals = float(meanNumberOfChemicals) # make sure the number is a float (numerical value) \n",
    "\n",
    "print(\"The average number of potentially hazardous chemicals companies place in their haircare products is {:.2f}\".format(meanNumberOfChemicals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the mean number of potentially hazardous chemicals placed in haircare products is 14.61. \n",
    "How can you have 0.61 of a product?\n",
    "This illustrates an important characteristic of the mean: the mean value does **not** need to be one of the values you collected in your dataset. \n",
    "As a uncertainty scientist (statistician, biostatistician, data scientist, etc.) who needs to summarize the number of chemicals haircare products in CA contain, you may write something like this. \n",
    "\n",
    "The CSCP has collected data on XX haircare products which can contain 68 potentially hazardous chemicals. The average number of chemicals companies place in haircare products is 14.6. \n",
    "\n",
    "Now that we understand one way to describe a numerical variables' typical value, let's focus on one way to describe how values may vary around that mean value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and standard deviation\n",
    "\n",
    "The variance (Var) and, much more easy to communicate, standard deviation (SD), are common ways we can describe a variable's spread or how far values vary around their mean.\n",
    "\n",
    "The variance is computed as \n",
    "\n",
    "\\begin{align}\n",
    "    \\text{Var}(X) = \\delta^{2}(X) = \\dfrac{ (x_{1} - \\bar{X})^{2} + (x_{2} - \\bar{X})^{2} + (x_{1} - \\bar{X})^{2} \\cdots + (x_{n} - \\bar{X})^{2}}{n-1}.\n",
    "\\end{align}\n",
    "We can write this more compactly using sigma notation as \n",
    "\n",
    "\\begin{align}\n",
    "    \\text{Var}(X) = \\dfrac{ \\sum_{i=1}^{n} (x_{i} - \\bar{X})^{2}}{n-1} .\n",
    "\\end{align}\n",
    "\n",
    "Let's build intuition about why the variance measures the \"spread\" or how much our data \"varies\". \n",
    "We can look just at a single term in the sum. \n",
    "For the first step, you compute the difference between a data point ($x_{i}$) and the mean $(\\bar{X})$\n",
    "\n",
    "\\begin{align}\n",
    "    (x_{i} - \\bar{X}). \n",
    "\\end{align}\n",
    "\n",
    "The difference between data points and their mean is a measure of distance---the distance from the most typical value generated from your variable $X$.\n",
    "But we may not be concerned about whether that distance is to the left (negative) or to the right (positive) of our mean. \n",
    "One way to ignore whether data points are negative or positive is to artificially make all distances positive, and one choice, the choice for variance, is to square these distances\n",
    "\n",
    "\\begin{align}\n",
    "    (x_{i} - \\bar X)^{2} .\n",
    "\\end{align}\n",
    "\n",
    "Finally, we can compute individual squared differences for each data point but it may be easier to understand if we had a summary metric.\n",
    "What is the typical or most common squared distance from the mean? \n",
    "To answer that question we can compute the mean squared difference,\n",
    "\n",
    "\\begin{align}\n",
    "    \\sum_{i=1}^{n} \\dfrac{(x_{i} - \\bar{X})^{2}}{n} .\n",
    "\\end{align}\n",
    "\n",
    "However (we'll see why in a later class) the mean squared difference most often underestimates our true variance ($\\sigma^2$).\n",
    "And as a correction we divide by $n-1$, increasing our estimate of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varNumberOfChemicals = sumOfChemsPerCompany.var()  # take variance of number of potenitally haz chemicals \n",
    "varNumberOfChemicals = float(varNumberOfChemicals) # make sure the number is a float (numerical value) \n",
    "\n",
    "print(\"The variance of potentially hazardous chemicals companies place in their haircare products is {:.2f}\".format(varNumberOfChemicals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance has an embarrassing problem: it is super hard to interpret.\n",
    "What is it saying? Why is it so hard to interpret?\n",
    "The biggest problem with interpreting the variance is the units.\n",
    "If we collect data $X$ measured in (say) inches, then the variance would measured in square inches (why?). \n",
    "\n",
    "To remedy this issue with units we can take the square root of the variance.\n",
    "This is called the standard deviation\n",
    "\n",
    "\\begin{align}\n",
    "    s^{2} = \\left [ \\sum_{i=1}^{n} \\dfrac{(x_{i} - \\bar{X})^{2}}{n-1} \\right ]^{1/2} .\n",
    "\\end{align}\n",
    "\n",
    "Lets see if the standard deviation is any easier to interpret in our example of the number of hazardous chemicals in haircare products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdNumberOfChemicals = sumOfChemsPerCompany.std()  # take std of number of potenitally haz chemicals \n",
    "stdNumberOfChemicals = float(stdNumberOfChemicals) # make sure the number is a float (numerical value) \n",
    "\n",
    "print(\"The standard deviation of potentially hazardous chemicals companies place in their haircare products is {:.2f}\".format(stdNumberOfChemicals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One summary of our data could be:\n",
    "CSCP reports that companies include 14.6 potentially hazardous chemicals across all their haircare products, and that this number of chemicals can vary to as little as 0 and as many as 762 (standard deviation = 61.8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## QSA: Is the minimum a statistic?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n",
    " \n",
    "A histogram displays on the horizontal axis a range of potential values of your data $(x_{1},x_{2},\\cdots,x_{R})$, where $R$ is the user-selected range of values, and on the vertical axis counts of the number of data points that could fall between two values.\n",
    "Order the range of potential values so that the smallest values is $x_{1}$ and the largest is x_{R}.\n",
    "Take the smallest and second smallest value $(x_{1},x_{2})$, count the number of data points that are less than $x_{2}$ and larger or equal to $x_{1}$, $C(x_{1},x_{2})$ and plot a bar that extends from zero up to $C(x_{1},x_{2})$.\n",
    "Continue this procedure for the 2nd and 3rd value, 3rd and 4th, up until x_{R-1} and x_{R}. \n",
    "\n",
    "We can build a histogram for the number of potentially hazardous chemicals reported by CSCP. \n",
    "For a range of potential number of chemicals, we will choose the values (often called bin edges) $0,5,10,15,\\cdots,25$ and $30,130,230,\\cdots 800$.\n",
    "I chose this range of values for two reasons: (i) to illustrate the bin edges are your choice and (ii) the majority of data points fall between 0 and 25, with just one value above 700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts,bins = np.histogram( sumOfChemsPerCompany.totalNumOfChems, bins= list(np.arange(0,25+5,5)) + list(np.arange(30,800+100,100)) )\n",
    "\n",
    "avgBins = [ 0.5*(x+y) for (x,y) in zip(bins,bins[1:])]\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "fig,axs = plt.subplots(1,2,sharey=True)\n",
    "\n",
    "ax=axs[0]\n",
    "for b,c in zip(avgBins,counts):\n",
    "    ax.plot([b]*2,[0,c],linewidth=5, color=\"blue\")\n",
    "ax.set_xlim(0,100)\n",
    "\n",
    "ax.set_ylabel(\"Number of companies\")\n",
    "\n",
    "ax=axs[1]\n",
    "for b,c in zip(avgBins,counts):\n",
    "    ax.plot([b]*2,[0,c],linewidth=5, color=\"blue\")\n",
    "ax.set_xlim(500,800)\n",
    "ax.set_xticks([600,700,800])\n",
    "ax.axvline(501,color='k',alpha=0.60)\n",
    "\n",
    "fig.text(x=0.50, y = 0.0, s = \"Num of potentially hazardous chemicals\", transform=fig.transFigure,ha='center')\n",
    "\n",
    "plt.subplots_adjust(wspace=0,bottom=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram quickly shows us the majority of companies include between $0$ and $5$ potentially hazardous chemicals across all their haircare products. Most companies include less than 25 chemicals, a small number include more than $75$, and one company includes more than $700$ chemicals across all products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on the histogram\n",
    "\n",
    "There area few standard terms uncertainty scientists use when they talk about histograms. \n",
    "\n",
    "### Mode and unimodal distributions\n",
    "The mode of a variable is the **most likely value** that variable will take.\n",
    "Let's look at two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2)\n",
    "\n",
    "ax=axs[0]\n",
    "\n",
    "samples = np.random.normal(0,1,500)\n",
    "counts,bounds,patches = ax.hist(samples,30)\n",
    "\n",
    "approx_mode = bounds[np.argmax(counts)]\n",
    "mostCounts = np.max(counts)\n",
    "\n",
    "if approx_mode <0:\n",
    "    ax.plot([ approx_mode*1.5, approx_mode ],[ mostCounts*1.1,mostCounts], lw=1)\n",
    "    ax.text( approx_mode*1.5,mostCounts*1.1,\"Mode\",fontsize=10,ha='right',va='center')\n",
    "else:\n",
    "    ax.plot([ approx_mode*0.5, approx_mode ],[ mostCounts*1.1,mostCounts], lw=1)\n",
    "    ax.text( approx_mode*0.5,mostCounts*1.1,\"Mode\",fontsize=10,ha='right',va='center')\n",
    "    \n",
    "    \n",
    "# second example\n",
    "ax=axs[1]\n",
    "\n",
    "samples00 = np.random.normal(0,0.5,500)\n",
    "samples01 = np.random.normal(-2,0.3,500)\n",
    "\n",
    "samples = list(samples00) + list(samples01)\n",
    "\n",
    "counts,bounds,patches = ax.hist(samples,30)\n",
    "\n",
    "approx_mode = bounds[np.argmax(counts)]\n",
    "mostCounts = np.max(counts)\n",
    "\n",
    "ax.plot([ approx_mode*0.75, approx_mode ],[ mostCounts*1.1,mostCounts], lw=1)\n",
    "ax.text( approx_mode*0.75,mostCounts*1.1,\"Mode\",fontsize=10,ha='left',va='center')\n",
    " \n",
    "fig.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution on the left has a single peak, a place where the number of observations is highest within a left and right bound. \n",
    "We can approximate the mode by this place where counts are highest.\n",
    "Distributions don't need to have a single peak (called **unimodel distributions**) to have a mode. \n",
    "Distributions can have several peaks (**multi-model distribution**) or other unusual qualities and still have a mode. \n",
    "\n",
    "## Symmetry and skew\n",
    "\n",
    "We would call a variable's distribution of observations **symmetric** is there is some vertical line such that the counts of values to the left of the vertical line mirror the counts of values to the right of the vertical line. \n",
    "A distribution that is not **symmetric** is called **asymmetric**. \n",
    "\n",
    "There are many types of **asymmetric** distributions. But two common ways to describe asymmetry when a distribution is unimodel are left and right skew.\n",
    "A distribution is **left skewed** if a small number of observations for a variable appear to the left of the mean. \n",
    "If there is a handful of observations that trail off to the right of the mean, the distribution could be described as having **right skew**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2)\n",
    "\n",
    "# right skewed dist\n",
    "ax = axs[0]\n",
    "\n",
    "samples = np.random.gamma(1,3,500)\n",
    "counts,bounds,patches = ax.hist(samples,25)\n",
    "\n",
    "ax.text( bounds[-3], (1+counts[-3])*10, \"Right Skew\"\n",
    "        , fontsize=12,weight=\"bold\", ha='right',va=\"bottom\")\n",
    "ax.tick_params(direction=\"in\")\n",
    "\n",
    "# left skewed dist\n",
    "ax = axs[1]\n",
    "\n",
    "samples = np.random.beta(10,2,500)\n",
    "counts,bounds,patches = ax.hist(samples,25,color=\"red\")\n",
    "\n",
    "ax.text( bounds[3], 5.*(counts[3]), \"Left Skew\"\n",
    "        , fontsize=12,weight=\"bold\", ha='left',va=\"bottom\")\n",
    "ax.tick_params(direction=\"in\")\n",
    "\n",
    "fig.set_size_inches(12,6)\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The barplot\n",
    "\n",
    "Categorical variables can be visualized by a barplot. \n",
    "The levels of the categorical variables are placed on the horizontal axis and, over top of each labeled level, a vertical bar is drawn corresponding to counts of observations that fall within each level.\n",
    "\n",
    "Below is an example of a barplot built for a categorical variables with 100 observations and three levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.choice(a=[0,1,2],p=[0.1,0.3,0.6],size=100) # generate some random data\n",
    "\n",
    "sns.countplot( data) # a barplot that uses counts like above is called a \"countplot\" in the Seaborn module\n",
    "plt.show()           # show us the plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships between variables\n",
    "\n",
    "Up until now the visualizations we discussed summary a single variabe from our dataset, but there are many visualizations that allow us to explore the relationships between more than a single variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot\n",
    "\n",
    "A scatter plot of two variables $X$ and $Y$ plots for each observation the point $(x_{i},y_{i})$ corresponding to the $i^{\\text{th}}$ observation. \n",
    "A scatter plot is useful for plotting two continuous variables.\n",
    "\n",
    "As an example, we will use data on the Aedes mosquito collected by the state of California in 2019.\n",
    "\n",
    "Found on all continents, and transported to the southern Unites States through global trade and shipping, the Aedes mosquito---carrying yellow and dengue fever, the Zika virus, and Chikungunya---infects nearly 100 million people world wide and causes millions of deaths every year. The CDC, in an effort to prevent US infections, disease burden, and deaths, has issued an open challenge to predict Aedes incidence in the US. Accurate prediction of Aedes can significantly reduce disease burden, warning public health officals of a potential epidemic before it is too late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # this module allows you to read in, and manipulate, a dataframe (data matrix)\n",
    "\n",
    "# These two modules (a set of pre-packaged functions) are very useful for plotting/viz in python \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# the read_csv function is a part of pandas, and allows us to read into Python a dataframe in csv format\n",
    "aedes = pd.read_csv(\"https://predict.cdc.gov/api/v1/attachments/aedes_challenge_2019/aedes_collections_california.csv\")\n",
    "print(aedes.head(5)) # this function allows us to print out 5 rows of our dataframe\n",
    "\n",
    "# Above we assigned the variable \"aedes\" to the dataframe containing infromation on counts of Albopictus and Aegypti mosquitoes captured in the state of California. \n",
    "\n",
    "# We can add new variables to a dataframe by writing the name of the dataframe, and inside square brackets, \n",
    "# the name of the variable we will create. For example, below two new variables were created\n",
    "# the first variable if called \"pct_aegypti\" and the second variable is called \"pct_albo\". \n",
    "aedes[\"pct_aegypti\"] = aedes.num_aegypti_collected / aedes.num_collection_events\n",
    "aedes[\"pct_albo\"]    = aedes.num_albopictus_collected / aedes.num_collection_events\n",
    "\n",
    "# we can also extract or refer to variables by calling the dataframe by name, a period, and then the variable name (see above)\n",
    "\n",
    "# Finally, we can select specific rows and specific columns from our dataset by writing the datafrmae name , a period, and the function loc. The function loc takes as input a logical expression for rows and a logical expression for columns separated by a comma.  \n",
    "# Below, we asked for all the rows where the variable \"pct_albo\" and the variable \"pct_aegypti\" are strictly greater than zero.  \n",
    "aedes_above0 = aedes.loc[ (aedes[\"pct_albo\"]>0) & (aedes[\"pct_aegypti\"]>0),: ]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=\"pct_albo\", y = \"pct_aegypti\" , data = aedes_above0,ax=ax )\n",
    "\n",
    "ax.set_xlabel(\"Percent Albopictus\")\n",
    "ax.set_ylabel(\"Percent Aegypti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box and whisker plot\n",
    "\n",
    "The box and whisker plots a set of statistics: the 25th percentile, 50th percentile, 75th percentile, and 1.5 times the interquartile range.\n",
    "The boxplot does not plot all observations from a dataframe and is useful for plotting a categorical variable against a continuous variable. \n",
    "\n",
    "#### Percentiles\n",
    "The $q^{\\text{th}}$ percentile of a variable $X$ is a **statistic** defined as the value $v$ such that $q$ percent of the values in $X$ are less than $v$. \n",
    "For example, the 25th percentile of $X$ is the value $v$ where \n",
    " $$\\frac{\\text{Number values below }v}{\\text{Number of values in }X } = 0.25  $$\n",
    " \n",
    "The 50th percentile is given a special name, the median. \n",
    "The **interquartile range (IQR)** is the 75th percentile minus the 25th percentile and is a measure of the spread of values for a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box and whisker plot\n",
    "fig,ax = plt.subplots()\n",
    "sns.boxplot(\"county\",\"pct_aegypti\", fliersize=0, data = aedes_above0,ax=ax)\n",
    "ax.set_ylim(0,4)\n",
    "\n",
    "ax.set_xlabel(\"County in CA\")\n",
    "ax.set_ylabel(\"Percent of Aegypti Mosquito captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each box corresponds to a different category (in our case county in CA) and the y axis represents a continuous variable (in our case the percentage of captures that contained the Aegypti mosquito). \n",
    "The top and bottom of each box corresponds to the 75th and 25th percentile. \n",
    "The line inside the box is the 50th percentile (median) and the bar below the box is equal to the 25th percentile minus 1.5 times the IQR and the bar above the box is equal to the 75th percneitle plus 1.5 times the IQR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
